# Reading List

[Conference Deadline](https://jackietseng.github.io/conference_call_for_paper/conferences.html) is the primary productive force.

## Relational Triple Extraction

1. **GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction**. *Tsu-Jui Fu, Peng-Hsuan Li, and Wei-Yun Ma*. ACL 2019. [pdf](https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf) [code](https://github.com/tsujuifu/pytorch_graph-rel)
2. **Entity-Relation Extraction as Multi-Turn Question Answering**. *Xiaoya Li, Fan Yin, Zijun Sun, Xiayu Li, Arianna Yuan, Duo Chai, Mingxin Zhou, Jiwei Li*. ACL 2019. [pdf](https://arxiv.org/pdf/1905.05529.pdf) [code](https://github.com/ShannonAI/Entity-Relation-As-Multi-Turn-QA)
3. **Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling**. *Dai Dai, Xinyan Xiao, Yajuan Lyu, Shan Dou, Qiaoqiao She, Haifeng Wang*. AAAI 2019. [pdf](https://aaai.org/ojs/index.php/AAAI/article/view/4591/4469)
4. **A Hierarchical Framework for Relation Extraction with Reinforcement Learning**. *Ryuichi Takanobu, Tianyang Zhang, Jiexi Liu, Minlie Huang*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.03925.pdf) [code](https://github.com/truthless11/HRL-RE)
5. **An Attention-based Model for Joint Extraction of Entities and Relations with Implicit Entity Features**. *Yan Zhou, Longtao Huang, Tao Guo, Songlin Hu, Jizhong Han*. WWW 2019 Companion. [pdf](https://dl.acm.org/citation.cfm?id=3317704)
6. **Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism**. *Xiangrong Zeng, Daojian Zeng, Shizhu He, Kang Liu, Jun Zhao*. ACL 2018. [pdf](https://www.aclweb.org/anthology/P18-1047) [code](https://github.com/xiangrongzeng/copy_re)
7. **Extracting Entities and Relations with Joint Minimum Risk Training**. *Changzhi Sun, Yuanbin Wu, Man Lan, Shiliang Sun*. EMNLP 2018. [pdf](https://www.aclweb.org/anthology/D18-1249) [code](https://github.com/changzhisun/entrel-joint-mrt)
8. **Adversarial training for multi-context joint entity and relation extraction**. *Giannis Bekoulis, Johannes Deleu, Thomas Demeester, Chris Develder*. EMNLP 2018. [pdf](https://www.aclweb.org/anthology/D18-1307v2) [code](https://github.com/bekou/multihead_joint_entity_relation_extraction)
9. **Joint Extraction of Entities and Relations Based on a Novel Graph Scheme**. *Shaolei Wang, Yue Zhang, Wanxiang Che, Ting Liu*. IJCAI 2018. [pdf](https://www.ijcai.org/proceedings/2018/0620.pdf) [code](https://github.com/hitwsl/joint-entity-relation)
10. **Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach**. *Liyuan Liu, Xiang Ren, Qi Zhu, Shi Zhi, Huan Gui, Heng Ji, Jiawei Han*. EMNLP 2017. [pdf](https://arxiv.org/pdf/1707.00166.pdf) [code](https://github.com/LiyuanLucasLiu/ReHession)
11. **End-to-End Neural Relation Extraction with Global Optimization**. *Meishan Zhang, Yue Zhang, Guohong Fu*. EMNLP 2017. [pdf](https://www.aclweb.org/anthology/D17-1182.pdf)
12. **Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme**. *Suncong Zheng, Feng Wang, Hongyun Bao, Yuexing Hao, Peng Zhou, Bo Xu*. ACL 2017. [pdf](https://arxiv.org/pdf/1706.05075.pdf) [code](https://github.com/zsctju/triplets-extraction)
13. **Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees**. *Arzoo Katiyar, Claire Cardie*. ACL 2017. [pdf](https://www.aclweb.org/anthology/P17-1085.pdf)
14. **CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases**. *Xiang Ren, Zeqiu Wu, Wenqi He, Meng Qu, Clare R. Voss, Heng Ji, Tarek F. Abdelzaher, Jiawei Han*. WWW 2017. [pdf](https://arxiv.org/pdf/1610.08763.pdf) [code](https://github.com/INK-USC/DS-RelationExtraction)
15. **End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures**. *Makoto Miwa, Mohit Bansal*. ACL 2016. [pdf](https://www.aclweb.org/anthology/P16-1105.pdf) [code](https://github.com/tticoin/LSTM-ER)
16. **Improved Relation Extraction with Feature-Rich Compositional Embedding Models**. *Matthew R. Gormley, Mo Yu, Mark Dredze*. EMNLP 2015. [pdf](https://www.aclweb.org/anthology/D15-1205.pdf)
17. **Modeling Joint Entity and Relation Extraction with Table Representation**. *Makoto Miwa, Yutaka Sasaki*. EMNLP 2014. [pdf](https://www.aclweb.org/anthology/D14-1200.pdf) [code](https://github.com/tticoin/JointER)
18. **Incremental Joint Extraction of Entity Mentions and Relations**. *Qi Li, Heng, Ji*. ACL 2014. [pdf](https://www.aclweb.org/anthology/P14-1038.pdf)
19. **Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations**. *Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, Daniel S. Weld*. ACL 2011. [pdf](https://www.aclweb.org/anthology/P11-1055.pdf) [code](http://raphaelhoffmann.com/mr/)

## General Seq2Seq (ner, pos, slot filling, etc.)

1. **GraphIE: A Graph-Based Framework for Information Extraction**. *Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, Regina Barzilay*. NAACL 2019. [pdf](https://arxiv.org/pdf/1810.13083.pdf) [code](https://github.com/thomas0809/GraphIE)
2. **FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling**. *Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli*. NAACL 2019. [pdf](https://arxiv.org/pdf/1904.01038.pdf) [code](https://github.com/pytorch/fairseq)
3. **BERT for Joint Intent Classification and Slot Filling**. *Qian Chen, Zhu Zhuo, Wen Wang*. Preprint 2019. [pdf](https://arxiv.org/pdf/1902.10909.pdf) [code](https://github.com/MahmoudWahdan/dialog-nlu)
4. **QA4IE: A Question Answering based Framework for Information Extraction**. *Lin Qiu, Hao Zhou, Yanru Qu, Weinan Zhang, Suoheng Li, Shu Rong, Dongyu Ru, Lihua Qian, Kewei Tu, Yong Yu*. ISWC 2018. [pdf](https://arxiv.org/pdf/1804.03396.pdf) [code](https://github.com/SJTU-lqiu/QA4IE)
5. **OpenTag: Open Attribute Value Extraction from Product Profiles**. *Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li*. SIGKDD 2018. [pdf](https://arxiv.org/pdf/1806.01264.pdf) 
6. **Deep Active Learning for Named Entity Recognition**. *Yanyao Shen, Hyokun Yun, Zachary C. Lipton, Yakov Kronrod, Animashree Anandkumar*. ICLR 2018. [pdf](https://openreview.net/pdf?id=ry018WZAZ)
7. **Semi-Supervised Sequence Modeling with Cross-View Training**. *Kevin Clark, Minh-Thang Luong, Christopher D. Manning, Quoc V. Le*. EMNLP 2018. [pdf](https://arxiv.org/pdf/1809.08370.pdf) [code](https://github.com/tensorflow/models/tree/master/research/cvt_text)
8. **Design Challenges and Misconceptions in Neural Sequence Labeling**. *Jie Yang, Shuailong Liang, Yue Zhang*. COLING 2018. [pdf](https://www.aclweb.org/anthology/C18-1327) [code](https://github.com/jiesutd/NCRFpp)
9. **Semi-supervised sequence tagging with bidirectional language models**. *Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power*. ACL 2017. [pdf](https://arxiv.org/pdf/1705.00108.pdf) [code](https://github.com/allenai/allennlp)
10. **Semi-supervised Multitask Learning for Sequence Labeling**. *Marek Rei*. ACL 2017. [pdf](https://arxiv.org/pdf/1704.07156.pdf) [code](https://github.com/marekrei/sequence-labeler)
11. **Leveraging Sentence-level Information with Encoder LSTM for Semantic Slot Filling**. *Gakuto Kurata, Bing Xiang, Bowen Zhou, Mo Yu*. EMNLP 2016. [pdf](https://www.aclweb.org/anthology/D16-1223)
12. **Attending to Characters in Neural Sequence Labeling Models**. *Marek Rei, Gamal K. O. Crichton, Sampo Pyysalo*. COLING 2016. [pdf](https://www.aclweb.org/anthology/C16-1030) [code](https://github.com/marekrei/sequence-labeler)
13. **Neural Architectures for Named Entity Recognition**. *Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, Chris Dyer*. NAACL 2016. [pdf](https://www.aclweb.org/anthology/N16-1030) [code](https://github.com/zalandoresearch/flair)
14. **End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF**. *Xuezhe Ma, Eduard Hovy*. ACL 2016. [pdf](https://aclweb.org/anthology/P16-1101) [code](https://github.com/jayavardhanr/End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial)
15. **Supertagging with LSTMs**. *Ashish Vaswani, Yonatan Bisk, Kenji Sagae, Ryan Musa*. NAACL 2016. [pdf](https://www.aclweb.org/anthology/N16-1027) 
16. **Understanding LSTM Networks**. *Christopher Olah*. Blog 2016. [blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

## Relation Classification/Extraction

1. **Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction**. *Christoph Alt, Marc HÃ¼bner, Leonhard Hennig*. [pdf](https://www.aclweb.org/anthology/P19-1134) [code](https://github.com/DFKI-NLP/DISTRE)
2. **Cross-relation Cross-bag Attention for Distantly-supervised Relation Extraction**. *Yujin Yuan, Liyuan Liu, Siliang Tang, Zhongfei Zhang, Yueting Zhuang, Shiliang Pu, Fei Wu, Xiang Ren*. AAAI 2019. [pdf](https://arxiv.org/pdf/1812.10604.pdf) [code](https://github.com/yuanyu255/PCNN_C2SA)
3. **Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention**. *Xu Han, Pengfei Yu, Zhiyuan Liu, Maosong Sun, Peng Li*. EMNLP 2018. [pdf](https://aclweb.org/anthology/D18-1247) [code](https://github.com/thunlp/HNRE)
4. **Multi-Task Transfer Learning for Weakly-Supervised Relation Extraction**. *Jing Jiang*. ACL 2009. [pdf](https://www.aclweb.org/anthology/P09-1114)

## Event Detection/Extraction/Prediction

1. **COMET: Commonsense Transformers for Automatic Knowledge Graph Construction**. *Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, Yejin Choi*. ACL 2019. [pdf](https://arxiv.org/pdf/1906.05317.pdf) [code](https://github.com/atcbosselut/comet-commonsense)
2. **ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning**. *Maarten Sap, Ronan LeBras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A. Smith, Yejin Choi*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.00146.pdf) [demo](https://homes.cs.washington.edu/~msap/atomic/)
3. **Collective Event Detection via a Hierarchical and Bias Tagging Networks with Gated Multi-level Attention Mechanisms**. *Yubo Chen, Hang Yang, Kang Liu, Jun Zhao, Yantao Jia*. EMNLP 2018. [pdf](https://www.aclweb.org/anthology/D18-1158) [code](https://github.com/yubochen/NBTNGMA4ED)
4. **Adaptive Scaling for Sparse Detection in Information Extraction**. *Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun*. ACL 2018. [pdf](https://aclweb.org/anthology/P18-1095) [code](https://github.com/sanmusunrise/AdaScaling)
5. **Constructing Narrative Event Evolutionary Graph for Script Event Prediction**. *Zhongyang Li, Xiao Ding, Ting Liu*. IJCAI 2018. [pdf](https://arxiv.org/pdf/1805.05081.pdf) [code](https://github.com/eecrazy/ConstructingNEEG_IJCAI_2018)
6. **Constructing and Embedding Abstract Event Causality Networks from Text Snippets**. *Sendong Zhao, Quan Wang, Sean Massung, Bing Qin, Ting Liu, Bin Wang, ChengXiang Zhai*. WSDM 2017. [pdf](http://ir.hit.edu.cn/~sdzhao/CausalEmbedding.pdf)

## Transformers

1. **XLNet: Generalized Autoregressive Pretraining for Language Understanding**. *Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le*. Preprint 2019. [pdf](https://arxiv.org/pdf/1906.08237.pdf) [code](https://github.com/zihangdai/xlnet)
2. **Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context**. *Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov*. ACL 2019. [pdf](https://arxiv.org/pdf/1901.02860.pdf) [code](https://github.com/kimiyoung/transformer-xl)
3. **Cross-lingual Language Model Pretraining**. *Guillaume Lample, Alexis Conneau*. Preprint 2019. [pdf](https://arxiv.org/pdf/1901.07291v1.pdf) [code](https://github.com/facebookresearch/XLM)
4. **Language Models are Unsupervised Multitask Learners**. *Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever*. Preprint 2019. [pdf](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) [code](https://github.com/openai/gpt-2)
5. **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**. *Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova*. NAACL 2019. [pdf](https://www.aclweb.org/anthology/N19-1423) [code](https://github.com/google-research/bert)
6. **Improving Language Understanding by Generative Pre-Training**.  *Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever*. Preprint 2018. [pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) [code](https://github.com/openai/finetune-transformer-lm)
7. **Attention Is All You Need**. *Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin*. NIPS 2017. [pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) [code](https://github.com/tensorflow/tensor2tensor)

## Knowledge Graph System

1. **T2KG: An End-to-End System for Creating Knowledge Graph from Unstructured Text**. *Natthawut Kertkeidkachorn, Ryutaro Ichise*. AAAI 2017 Workshop. [pdf](https://www.aaai.org/ocs/index.php/WS/AAAIW17/paper/download/15129/14743) [demo](https://sites.google.com/view/t2kg-demo/home)

## Representation learning

1. **PyTorch-BigGraph: A Large-scale Graph Embedding System**. *Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, Alex Peysakhovich*. SysML 2019. [pdf](https://www.sysml.cc/doc/2019/71.pdf) [code](https://github.com/facebookresearch/PyTorch-BigGraph)
2. **One-Shot Relational Learning for Knowledge Graphs**. *Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang*. EMNLP 2018. [pdf](https://arxiv.org/pdf/1808.09040.pdf) [code](https://github.com/xwhan/One-shot-Relational-Learning)

## General Multi-task Learning

1. **A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks**. *Victor Sanh, Thomas Wolf, Sebastian Ruder*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.06031.pdf) [code](https://github.com/huggingface/hmtl)
2. **An Overview of Multi-Task Learning in Deep Neural Networks**. *Sebastian Ruder*. Preprint 2017. [pdf](https://arxiv.org/pdf/1706.05098.pdf)

## Others

1. **Awesome-knowledge-graph**. *BrambleXu*. Github Repo. [github [recommended]](https://github.com/BrambleXu/knowledge-graph-learning)
2. **åºäºDGCNNåæ¦çå¾çè½»éçº§ä¿¡æ¯æ½åæ¨¡å**. *èåæ*. Blog 2019. [blog](https://spaces.ac.cn/archives/6671) [code](https://github.com/bojone/kg-2019)
3. **ä¸­æèªç¶è¯­è¨å¤çæ°æ®éåè¡¨**. *InsaneLife*. GitHub Repo. [github](https://github.com/InsaneLife/ChineseNLPCorpus)
4. **æ·±åº¦å­¦ä¹ 500é®**. *Tan Jiyong*. Github Repo. [github](https://github.com/scutan90/DeepLearning-500-questions)
5. **æ·±åº¦å­¦ä¹ ä¸èªç¶è¯­è¨å¤çãç¥è¯å¾è°±ãå¯¹è¯ç³»ç»**. *Li hanghang*. GitHub Repo. [github](https://github.com/lihanghang/Knowledge-Graph)
