# Reading List 
## [Conference Deadlines](https://jackietseng.github.io/conference_call_for_paper/conferences.html)
## Relational Triple Extraction

1. **Entity-Relation Extraction as Multi-Turn Question Answering**. *Xiaoya Li, Fan Yin, Zijun Sun, Xiayu Li, Arianna Yuan, Duo Chai, Mingxin Zhou, Jiwei Li*. ACL 2019. [pdf](https://arxiv.org/pdf/1905.05529.pdf) [code](https://github.com/ShannonAI/Entity-Relation-As-Multi-Turn-QA)
2. **GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction**. *Tsu-Jui Fu, Peng-Hsuan Li, and Wei-Yun Ma*. ACL 2019. [pdf](https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf) [code](https://github.com/tsujuifu/pytorch_graph-rel)
3. **A Hierarchical Framework for Relation Extraction with Reinforcement Learning**. *Ryuichi Takanobu, Tianyang Zhang, Jiexi Liu, Minlie Huang*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.03925.pdf) [code](https://github.com/truthless11/HRL-RE)
4. **Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism**. *Xiangrong Zeng, Daojian Zeng, Shizhu He, Kang Liu, Jun Zhao*. ACL 2018. [pdf](https://www.aclweb.org/anthology/P18-1047) [code](https://github.com/xiangrongzeng/copy_re)
5. **Adversarial training for multi-context joint entity and relation extraction**. *Giannis Bekoulis, Johannes Deleu, Thomas Demeester, Chris Develder*. EMNLP 2018. [pdf](https://www.aclweb.org/anthology/D18-1307v2) [code](https://github.com/bekou/multihead_joint_entity_relation_extraction)
6. **Joint Extraction of Entities and Relations Based on a Novel Graph Scheme**. *Shaolei Wang, Yue Zhang, Wanxiang Che, Ting Liu*. IJCAI 2018. [pdf](http://ir.hit.edu.cn/~car/papers/ijcai18slwang.pdf) [code](https://github.com/hitwsl/joint-entity-relation)
7. **Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme**. *Suncong Zheng, Feng Wang, Hongyun Bao, Yuexing Hao, Peng Zhou, Bo Xu*. ACL 2017. [pdf](https://arxiv.org/pdf/1706.05075.pdf) [code](https://github.com/zsctju/triplets-extraction)
8. **CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases**. *Xiang Ren, Zeqiu Wu, Wenqi He, Meng Qu, Clare R. Voss, Heng Ji, Tarek F. Abdelzaher, Jiawei Han*. WWW 2017. [pdf](https://arxiv.org/pdf/1610.08763.pdf) [code](https://github.com/INK-USC/DS-RelationExtraction)

## General Seq2Seq (ner, pos, slot filling, etc.)

1. **GraphIE: A Graph-Based Framework for Information Extraction**. *Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, Regina Barzilay*. NAACL 2019. [pdf](https://arxiv.org/pdf/1810.13083.pdf) [code](https://github.com/thomas0809/GraphIE)
2. **FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling**. *Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli*. NAACL 2019. [pdf](https://arxiv.org/pdf/1904.01038.pdf) [code](https://github.com/pytorch/fairseq)
3. **BERT for Joint Intent Classification and Slot Filling**. *Qian Chen, Zhu Zhuo, Wen Wang*. Preprint 2019. [pdf](https://arxiv.org/pdf/1902.10909.pdf) [code](https://github.com/MahmoudWahdan/dialog-nlu)
4. **OpenTag: Open Attribute Value Extraction from Product Profiles**. *Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li*. SIGKDD 2018. [pdf](https://arxiv.org/pdf/1806.01264.pdf) 
5. **Deep Active Learning for Named Entity Recognition**. *Yanyao Shen, Hyokun Yun, Zachary C. Lipton, Yakov Kronrod, Animashree Anandkumar*. ICLR 2018. [pdf](https://openreview.net/pdf?id=ry018WZAZ)
6. **Semi-Supervised Sequence Modeling with Cross-View Training**. *Kevin Clark, Minh-Thang Luong, Christopher D. Manning, Quoc V. Le*. EMNLP 2018. [pdf](https://arxiv.org/pdf/1809.08370.pdf) [code](https://github.com/tensorflow/models/tree/master/research/cvt_text)
7. **Design Challenges and Misconceptions in Neural Sequence Labeling**. *Jie Yang, Shuailong Liang, Yue Zhang*. COLING 2018. [pdf](https://www.aclweb.org/anthology/C18-1327) [code](https://github.com/jiesutd/NCRFpp)
8. **Semi-supervised sequence tagging with bidirectional language models**. *Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power*. ACL 2017. [pdf](https://arxiv.org/pdf/1705.00108.pdf) [code](https://github.com/allenai/allennlp)
9. **Semi-supervised Multitask Learning for Sequence Labeling**. *Marek Rei*. ACL 2017. [pdf](https://arxiv.org/pdf/1704.07156.pdf) [code](https://github.com/marekrei/sequence-labeler)
10. **Leveraging Sentence-level Information with Encoder LSTM for Semantic Slot Filling**. *Gakuto Kurata, Bing Xiang, Bowen Zhou, Mo Yu*. EMNLP 2016. [pdf](https://www.aclweb.org/anthology/D16-1223)
11. **Attending to Characters in Neural Sequence Labeling Models**. *Marek Rei, Gamal K. O. Crichton, Sampo Pyysalo*. COLING 2016. [pdf](https://www.aclweb.org/anthology/C16-1030) [code](https://github.com/marekrei/sequence-labeler)
12. **Neural Architectures for Named Entity Recognition**. *Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, Chris Dyer*. NAACL 2016. [pdf](https://www.aclweb.org/anthology/N16-1030) [code](https://github.com/zalandoresearch/flair)
13. **End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF**. *Xuezhe Ma, Eduard Hovy*. ACL 2016. [pdf](https://aclweb.org/anthology/P16-1101) [code](https://github.com/jayavardhanr/End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial)
14. **Supertagging with LSTMs**. *Ashish Vaswani, Yonatan Bisk, Kenji Sagae, Ryan Musa*. NAACL 2016. [pdf](https://www.aclweb.org/anthology/N16-1027) 
15. **Understanding LSTM Networks**. *Christopher Olah*. Blog 2016. [blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

## Relation Classification/Extraction

1. **Cross-relation Cross-bag Attention for Distantly-supervised Relation Extraction**. *Yujin Yuan, Liyuan Liu, Siliang Tang, Zhongfei Zhang, Yueting Zhuang, Shiliang Pu, Fei Wu, Xiang Ren*. AAAI 2019. [pdf](https://arxiv.org/pdf/1812.10604.pdf) [code](https://github.com/yuanyu255/PCNN_C2SA)
2. **Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention**. *Xu Han, Pengfei Yu, Zhiyuan Liu, Maosong Sun, Peng Li*. EMNLP 2018. [pdf](https://aclweb.org/anthology/D18-1247) [code](https://github.com/thunlp/HNRE)
3. **Multi-Task Transfer Learning for Weakly-Supervised Relation Extraction**. *Jing Jiang*. ACL 2009. [pdf](https://www.aclweb.org/anthology/P09-1114)

## Event Detection/Extraction/Prediction

1. **COMET: Commonsense Transformers for Automatic Knowledge Graph Construction**. *Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, Yejin Choi*. ACL 2019. [pdf](https://arxiv.org/pdf/1906.05317.pdf) [code](https://github.com/atcbosselut/comet-commonsense)
2. **ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning**. *Maarten Sap, Ronan LeBras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A. Smith, Yejin Choi*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.00146.pdf) [demo](https://homes.cs.washington.edu/~msap/atomic/)
3. **Collective Event Detection via a Hierarchical and Bias Tagging Networks with Gated Multi-level Attention Mechanisms**. *Yubo Chen, Hang Yang, Kang Liu, Jun Zhao, Yantao Jia*. EMNLP 2018. [pdf](https://www.aclweb.org/anthology/D18-1158) [code](https://github.com/yubochen/NBTNGMA4ED)
4. **Adaptive Scaling for Sparse Detection in Information Extraction**. *Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun*. ACL 2018. [pdf](https://aclweb.org/anthology/P18-1095) [code](https://github.com/sanmusunrise/AdaScaling)
5. **Constructing Narrative Event Evolutionary Graph for Script Event Prediction**. *Zhongyang Li, Xiao Ding, Ting Liu*. IJCAI 2018. [pdf](https://arxiv.org/pdf/1805.05081.pdf) [code](https://github.com/eecrazy/ConstructingNEEG_IJCAI_2018)
6. **Constructing and Embedding Abstract Event Causality Networks from Text Snippets**. *Sendong Zhao, Quan Wang, Sean Massung, Bing Qin, Ting Liu, Bin Wang, ChengXiang Zhai*. WSDM 2017. [pdf](http://ir.hit.edu.cn/~sdzhao/CausalEmbedding.pdf)

## Transformers

1. **XLNet: Generalized Autoregressive Pretraining for Language Understanding**. *Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le*. Preprint 2019. [pdf](https://arxiv.org/pdf/1906.08237.pdf) [code](https://github.com/zihangdai/xlnet)
2. **Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context**. *Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov*. ACL 2019. [pdf](https://arxiv.org/pdf/1901.02860.pdf) [code](https://github.com/kimiyoung/transformer-xl)
3. **Cross-lingual Language Model Pretraining**. *Guillaume Lample, Alexis Conneau*. Preprint 2019. [pdf](https://arxiv.org/pdf/1901.07291v1.pdf) [code](https://github.com/facebookresearch/XLM)
4. **Language Models are Unsupervised Multitask Learners**. *Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever*. Preprint 2019. [pdf](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) [code](https://github.com/openai/gpt-2)
5. **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**. *Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova*. NAACL 2019. [pdf](https://www.aclweb.org/anthology/N19-1423) [code](https://github.com/google-research/bert)
6. **Improving Language Understanding by Generative Pre-Training**.  *Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever*. Preprint 2018. [pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) [code](https://github.com/openai/finetune-transformer-lm)
7. **Attention Is All You Need**. *Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin*. NIPS 2017. [pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) [code](https://github.com/tensorflow/tensor2tensor)

## Representation learning

1. **PyTorch-BigGraph: A Large-scale Graph Embedding System**. *Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, Alex Peysakhovich*. SysML 2019. [pdf](https://www.sysml.cc/doc/2019/71.pdf) [code](https://github.com/facebookresearch/PyTorch-BigGraph)
2. **One-Shot Relational Learning for Knowledge Graphs**. *Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang*. EMNLP 2018. [pdf](https://arxiv.org/pdf/1808.09040.pdf) [code](https://github.com/xwhan/One-shot-Relational-Learning)

## General Multi-task Learning

1. **A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks**. *Victor Sanh, Thomas Wolf, Sebastian Ruder*. AAAI 2019. [pdf](https://arxiv.org/pdf/1811.06031.pdf) [code](https://github.com/huggingface/hmtl)
2. **An Overview of Multi-Task Learning in Deep Neural Networks**. *Sebastian Ruder*. Preprint 2017. [pdf](https://arxiv.org/pdf/1706.05098.pdf)

## Others

1. **基于DGCNN和概率图的轻量级信息抽取模型**. *苏剑林*. Blog 2019. [blog](https://spaces.ac.cn/archives/6671) [code](https://github.com/bojone/kg-2019)
